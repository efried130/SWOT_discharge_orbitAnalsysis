{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec638c4f-b620-45d7-83b2-fa6b73a031d6",
   "metadata": {},
   "source": [
    "# Orbit Gauge Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1adf5a-43ca-4107-b785-67a10dc93e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Credit to Nikki Tebaldi, https://podaac.github.io/tutorials/notebooks/datasets/SWOT_L4_DAWG_SOS_DISCHARGE.html#plot-discharge-timeseries\n",
    "import datetime\n",
    "import time\n",
    "import pathlib\n",
    "import os,sys\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cartopy\n",
    "import geopandas as gpd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import folium\n",
    "import requests\n",
    "from io import StringIO\n",
    "import h5py\n",
    "import math\n",
    "import zipfile\n",
    "from datetime import timedelta\n",
    "import json\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "from tqdm import tqdm \n",
    "from itertools import islice\n",
    "from scipy.stats import pearsonr\n",
    "from itertools import combinations\n",
    "from scipy.stats import genextreme\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy import stats\n",
    "from scipy.stats import median_abs_deviation, shapiro, ttest_1samp, wilcoxon\n",
    "\n",
    "#Specialized Functions\n",
    "from swotOrbitFunctions_gauged import *\n",
    "\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 30,    # Title font size\n",
    "    'axes.labelsize': 22,     # Axis labels font size\n",
    "    'xtick.labelsize': 20,    # X-axis ticks font size\n",
    "    'ytick.labelsize': 20,    # Y-axis ticks font size\n",
    "    'legend.fontsize': 20,    # Legend font size\n",
    "    'font.size': 20,          # Global font size for text\n",
    "    'figure.titlesize': 24,   # Figure title font size\n",
    "    'lines.linewidth': 2,     # Line width\n",
    "    'axes.linewidth': 2,      # Axis line width\n",
    "    'axes.grid': True,        # Show grid\n",
    "    'grid.linestyle': '--',   # Dashed grid lines\n",
    "    'grid.alpha': 0.5,        # Grid line transparency\n",
    "    'figure.figsize': (10, 6) # Figure size (width, height in inches)\n",
    "})\n",
    "\n",
    "\n",
    "        \n",
    "color_dict = {\n",
    "    'sic4dvar': 'green',\n",
    "    'momma': 'blue',\n",
    "    'neobam': 'purple',\n",
    "    'consensus': 'sienna',\n",
    "    'metroman': 'orange',\n",
    "    'geobam': 'purple',\n",
    "    'hivdi': 'deeppink',\n",
    "    'sad': 'tomato',\n",
    "    'gauge': 'dimgrey',\n",
    "    'gauge_swot_match': 'silver'\n",
    "}\n",
    "\n",
    "color_dict_runCombos = {\n",
    "    'Continuous': '#D83A34',\n",
    "    'Fast': '#FD8500',\n",
    "    'Science': '#2B9EB3',\n",
    "    'Sampled': '#6610F2',\n",
    "    'gauge': 'black',\n",
    "    'Continuous-FSO': '#FFEE32',\n",
    "    'Continuous-SO': 'blue',\n",
    "}\n",
    "\n",
    "divide_date = pd.to_datetime('2023-07-11')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22295a-eb27-4127-9734-9dfc856df9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL Gauge Matched\n",
    "\n",
    "runA_perm_gauge = pd.read_csv('/all_gauge_a').drop_duplicates().dropna(subset='time')\n",
    "runB_perm_gauge = pd.read_csv('/all_gauge_b').drop_duplicates().dropna(subset='time')\n",
    "runC_perm_gauge = pd.read_csv('/all_gauge_c').drop_duplicates().dropna(subset='time')\n",
    "runE_perm_gauge = pd.read_csv('/all_gauge_e').drop_duplicates().dropna(subset='time')\n",
    "runE_perm_gauge =runE_perm_gauge[pd.to_datetime(runE_perm_gauge['time']) < divide_date]\n",
    "runA_perm_gauge =runA_perm_gauge[pd.to_datetime(runA_perm_gauge['time']) < divide_date]\n",
    "\n",
    "# Add continuous orbit split\n",
    "runC_perm_gauge_fast = runC_perm_gauge[pd.to_datetime(runC_perm_gauge['time']) < divide_date]\n",
    "runC_perm_gauge_science = runC_perm_gauge[pd.to_datetime(runC_perm_gauge['time']) >= divide_date]\n",
    "\n",
    "dfs_gauge = {\n",
    "    'Fast': runA_perm_gauge,\n",
    "    'Science': runB_perm_gauge,\n",
    "    'Continuous': runC_perm_gauge,\n",
    "    'Sampled': runE_perm_gauge,\n",
    "    'Continuous-FSO': runC_perm_gauge_fast,\n",
    "    'Continuous-SO': runC_perm_gauge_science\n",
    "}\n",
    "\n",
    "for label, df in dfs_gauge.items():\n",
    "    df['algo'] = df['algo'].replace({'geobam': 'neobam'})\n",
    "    df = calc_cons(df=df)\n",
    "    valid_reaches = df.loc[(df['algo'] == 'gauge') & (df['gauge_discharge'].notna()), 'reach_id'].unique()\n",
    "    runE_perm_gauge = df[df['reach_id'].isin(valid_reaches)]\n",
    "\n",
    "    dfs_gauge[label] = df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41faf638-3121-476a-80a5-d300fc8668ec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CV Filtering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38766ac0-e015-462d-8a16-3ae004d7bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIAL CV - calc metrics and plot proposed change\n",
    "# dfs_gauge_swot_metrics = {}\n",
    "# for label, df in filtered_dfs.items():\n",
    "#     df = calculate_metrics(df=df, reaches=list(df.reach_id.unique()))\n",
    "#     dfs_gauge_swot_metrics[label] = df \n",
    "#     print('done: ', label)\n",
    "    \n",
    "dfs_gauge_swot_metrics =append_RMD(dfs_q=dfs_gauge_swot)\n",
    "dfs_gauge_swot_metrics = append_coeffVar(dfs_q=dfs_gauge_swot_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f91e005-3347-4fa2-b2f5-d9d6c3ed9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CV figures\n",
    "\n",
    "algo_threshold=0.25\n",
    "algo_threshold2=0.4\n",
    "\n",
    "summary_df, rejected_data = plot_metric_cdfs_with_filters(\n",
    "    df=dfs_gauge_swot_metrics['Continuous'],\n",
    "    algo='consensus',\n",
    "    algo_threshold=algo_threshold,\n",
    "    algo_threshold2=algo_threshold2\n",
    ")\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be37d2d-6e1c-4942-8e57-e9435ebc3dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rejected Rach ID analysis\n",
    "\n",
    "    \n",
    "plot_reach_id_counts_by_algo(\n",
    "    df_orig = dfs_gauge_swot_metrics['Continuous'],\n",
    "    df=rejected_data[f'CV > {algo_threshold}'],\n",
    "    filter_condition =f'CV > {algo_threshold}',\n",
    "    color_dict=color_dict,\n",
    "    exclude_algos=['gauge', 'consensus']\n",
    ")\n",
    "plot_reach_id_counts_by_algo(\n",
    "    df_orig = dfs_gauge_swot_metrics['Continuous'],\n",
    "    df=rejected_data[f'CV > {algo_threshold2}'],\n",
    "    filter_condition =f'CV > {algo_threshold2}',\n",
    "    color_dict=color_dict,\n",
    "    exclude_algos=['gauge', 'consensus']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1096c255-aebb-42ea-ac23-d402ec2b4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rejected reach hydrographs\n",
    "# Assuming 'df_metrics' contains the necessary discharge and metrics data\n",
    "plot_discharge_with_metrics(df_metrics=rejected_data[f'CV > {algo_threshold}'], divide_date=pd.to_datetime('2023-07-11'), color_dict=color_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dd8026-c26e-4db4-a4fd-d30bd7964b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NOW DO CV FILTERING ON ACTUAL DATA\n",
    "for label, df in dfs_gauge.items():\n",
    "    df['algo'] = df['algo'].replace({'geobam': 'neobam'})\n",
    "    df = calc_cons(df=df)\n",
    "    dfs_gauge[label] = df \n",
    "print(dfs_gauge['Science'].algo.unique())\n",
    "\n",
    "dfs_gauge =append_RMD(dfs_q=dfs_gauge)\n",
    "dfs_gauge = append_coeffVar(dfs_q=dfs_gauge)\n",
    "\n",
    "dfs_gauge = remove_low_cv_and_recalc_consensus(dfs_gauge, CV_thresh = 0.25)\n",
    "\n",
    "for label, df in dfs_gauge.items():\n",
    "        df = df.drop(columns=['CV', 'CV_cons', 'CV_gauge','RMD_cons'])\n",
    "        dfs_gauge[label] = df  # Save the modified DataFrame back\n",
    "        \n",
    "dfs_gauge =append_RMD(dfs_q=dfs_gauge)\n",
    "dfs_gauge = append_coeffVar(dfs_q=dfs_gauge)\n",
    "\n",
    "print(dfs_gauge['Science'])\n",
    "\n",
    "for label, df in dfs_gauge.items():\n",
    "    df = calculate_metrics(df=df, reaches=list(df.reach_id.unique()))\n",
    "    dfs_gauge[label] = df\n",
    "    print('done calculating metrics for :', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410a0a4-479d-4847-b2b2-cfde76552a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALL Gauge FullRaNGE\n",
    "\n",
    "runA_perm_fullRange = pd.read_csv('/all_gauge_fullRange_a.csv').drop_duplicates().dropna(subset='time')\n",
    "runB_perm_fullRange = pd.read_csv('/all_gauge_fullRange_b.csv').drop_duplicates().dropna(subset='time')\n",
    "runC_perm_fullRange = pd.read_csv('/all_gauge_fullRange_c.csv').drop_duplicates().dropna(subset='time')\n",
    "runE_perm_fullRange = pd.read_csv('/all_gauge_fullRange_e.csv').drop_duplicates().dropna(subset='time')\n",
    "runA_perm_fullRange =runA_perm_fullRange[pd.to_datetime(runA_perm_fullRange['time']) < divide_date]\n",
    "runE_perm_fullRange =runE_perm_fullRange[pd.to_datetime(runE_perm_fullRange['time']) < divide_date]\n",
    "\n",
    "\n",
    "#Add continous orbit split\n",
    "runC_perm_fullRange_fast = runC_perm_fullRange[pd.to_datetime(runC_perm_fullRange['time']) < divide_date]\n",
    "runC_perm_fullRange_science = runC_perm_fullRange[pd.to_datetime(runC_perm_fullRange['time']) >= divide_date]\n",
    "\n",
    "\n",
    "dfs_gauge_fullRange = {'Fast': runA_perm_fullRange, 'Science': runB_perm_fullRange, 'Continuous': runC_perm_fullRange, 'Sampled': runE_perm_fullRange, 'Continuous-FSO': runC_perm_fullRange_fast, f'Continuous-SO': runC_perm_fullRange_science}\n",
    "\n",
    "\n",
    "for label, df in dfs_gauge_fullRange.items():\n",
    "    df['algo'] = df['algo'].replace({'geobam': 'neobam'})\n",
    "    df = calc_cons(df=df)\n",
    "    valid_reaches = df.loc[(df['algo'] == 'gauge') & (df['gauge_discharge'].notna()), 'reach_id'].unique()\n",
    "    runE_perm_gauge = df[df['reach_id'].isin(valid_reaches)]\n",
    "    \n",
    "    dfs_gauge_fullRange[label] = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68ab26-a926-42d2-9179-bdb61f55c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs_gauge_fullRange = append_RMD(dfs_q=dfs_gauge_fullRange)\n",
    "dfs_gauge_fullRange = append_coeffVar(dfs_q=dfs_gauge_fullRange)\n",
    "    \n",
    "\n",
    "dfs_gauge_fullRange = remove_low_cv_and_recalc_consensus(dfs_gauge_fullRange, CV_thresh = 0.25)\n",
    "\n",
    "for label, df in dfs_gauge_fullRange.items():\n",
    "        df = df.drop(columns=['CV', 'CV_cons', 'CV_gauge','RMD_cons'])\n",
    "        dfs_gauge_fullRange[label] = df  # Save the modified DataFrame back\n",
    "\n",
    "\n",
    "dfs_gauge_fullRange =append_RMD(dfs_q=dfs_gauge_fullRange)\n",
    "dfs_gauge_fullRange = append_coeffVar(dfs_q=dfs_gauge_fullRange)\n",
    "\n",
    "print(dfs_gauge_fullRange['Fast'])\n",
    "\n",
    "for label, df in dfs_gauge_fullRange.items():\n",
    "    df = calculate_metrics(df=df, reaches=list(df.reach_id.unique()))\n",
    "    dfs_gauge_fullRange[label] = df\n",
    "    print('done calculating metrics for :', label)\n",
    "\n",
    "for label, df in dfs_gauge.items():\n",
    "# Filter only 'gauge' rows\n",
    "    #df['algo'] = df['algo'].replace('gauge', 'gauge_swot_match')\n",
    "    df.loc[df['algo'] == 'gauge', 'algo'] = 'gauge_swot_match'\n",
    "    gauge_rows = df[df['algo'] == 'gauge_swot_match'].copy()\n",
    "    \n",
    "    # Rename 'algo' to 'gauge_swot_match'\n",
    "    # Append to target\n",
    "    dfs_gauge_fullRange[label] = pd.concat([dfs_gauge_fullRange[label], gauge_rows], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade244a5-e08d-4432-9183-c16ed95295dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVE AS NEEDED\n",
    "# pd.DataFrame(dfs_gauge_fullRange['Fast']).to_csv('//data/abcd_perm/dfs_gauge_fullRange_a_perm_filtered.csv', index=False)\n",
    "# pd.DataFrame(dfs_gauge_fullRange['Science']).to_csv('//data/abcd_perm/dfs_gauge_fullRange_b_perm_filtered.csv', index=False)\n",
    "# pd.DataFrame(dfs_gauge_fullRange['Continuous']).to_csv('//data/abcd_perm/dfs_gauge_fullRange_c_perm_filtered.csv', index=False)\n",
    "# pd.DataFrame(dfs_gauge_fullRange['Sampled']).to_csv('//data/abcd_perm/dfs_gauge_fullRange_e_perm_filtered.csv', index=False)\n",
    "\n",
    "\n",
    "# pd.DataFrame(dfs_gauge['Fast']).to_csv('//data/abcd_perm/dfs_gauge_a_perm_filtered.csv', index=False)\n",
    "# pd.DataFrame(dfs_gauge['Science']).to_csv('//data/abcd_perm/dfs_gauge_b_perm_filtered.csv', index=False)\n",
    "# pd.DataFrame(dfs_gauge['Continuous']).to_csv('//data/abcd_perm/dfs_gauge_c_perm_filtered.csv', index=False)\n",
    "# pd.DataFrame(dfs_gauge['Sampled']).to_csv('//data/abcd_perm/dfs_gauge_e_perm_filtered.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae71edd-6344-42bd-a755-df0a140513b8",
   "metadata": {
    "papermill": {
     "duration": 0.015357,
     "end_time": "2025-04-07T15:25:53.788623",
     "exception": false,
     "start_time": "2025-04-07T15:25:53.773266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hydrographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece27dd-d818-4152-951f-94417209162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot quad plot of reach IDs\n",
    "\n",
    "\n",
    "quad_reach_ids = [78100600061, 23214100051, 81390400111,74294400231] #74294400031,  ]\n",
    "# Color dictionary\n",
    "# color_dict_timeseries = {\n",
    "#     'Fast': 'lightskyblue', \n",
    "#     'Science': 'mediumblue', \n",
    "#     'Continuous': 'darkviolet', \n",
    "#     'Sampled': 'crimson', \n",
    "#     'gauge': 'darkgrey'\n",
    "# }\n",
    "color_dict_timeseries = {\n",
    "    'Continuous': '#D83A34',\n",
    "    'Fast': '#FD8500',\n",
    "    'Science': '#2B9EB3',\n",
    "    'Sampled': '#6610F2',\n",
    "    'gauge': 'black'\n",
    "}\n",
    "plot_quad_consensus(\n",
    "    dfs_dict=dfs_gauge_fullRange,\n",
    "    labels=labels,\n",
    "    divide_date=pd.to_datetime('2023-07-11'),\n",
    "    color_dict=color_dict_timeseries,\n",
    "    algo='consensus',\n",
    "    reach_ids=quad_reach_ids\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9a1316-f0ba-413b-bf38-1c3f38ef1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all hydrographs, edit funciton for certain reach IDs\n",
    "\n",
    "labels = ['Fast', 'Science', 'Continuous', 'Sampled', 'gauge']\n",
    "\n",
    "color_dict_timeseries = {\n",
    "    'Continuous': '#D83A34',\n",
    "    'Fast': '#FD8500',\n",
    "    'Science': '#2B9EB3',\n",
    "    'Sampled': '#6610F2',\n",
    "    'gauge': 'black'\n",
    "}\n",
    "\n",
    "plot_consensus_from_multiple_dfs(\n",
    "    dfs_dict=dfs_gauge_fullRange,\n",
    "    labels=labels,\n",
    "    divide_date=pd.to_datetime('2023-07-11'),\n",
    "    color_dict=color_dict_timeseries,\n",
    "    algo='consensus'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3589c-054b-48d1-a15e-e427395f985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print statistics for dfs_gauge\n",
    "\n",
    "# 1. Find common gauges across Fast, Science, and Continuous\n",
    "runs_to_compare = ['Fast', 'Continuous', 'Science']\n",
    "reach_ids_by_run = {}\n",
    "\n",
    "for label in runs_to_compare:\n",
    "    if label in dfs_gauge:\n",
    "        df = dfs_gauge[label].copy()\n",
    "        reach_ids = set(df['reach_id'].unique())\n",
    "        reach_ids_by_run[label] = reach_ids\n",
    "        print(f\"Total gauges in {label}: {len(reach_ids)}\")\n",
    "\n",
    "# Find intersection\n",
    "if len(reach_ids_by_run) == 3:\n",
    "    common_reach_ids = reach_ids_by_run['Fast'].intersection(\n",
    "        reach_ids_by_run['Science']).intersection(reach_ids_by_run['Continuous'])\n",
    "    print(f\"\\nGauges that overlap Fast/Science/Continuous: {len(common_reach_ids)}\")\n",
    "\n",
    "# 2. Print total gauges in Sampled if available\n",
    "if 'Sampled' in dfs_gauge:\n",
    "    sampled_reach_ids = set(dfs_gauge['Sampled']['reach_id'].unique())\n",
    "    print(f\"Total gauges in Sampled: {len(sampled_reach_ids)}\")\n",
    "\n",
    "# 3. Find gauges with data before 2023-07-12 in Continuous orbit\n",
    "if 'Continuous' in dfs_gauge:\n",
    "    df_cont = dfs_gauge['Continuous'].copy()\n",
    "    df_cont['time'] = pd.to_datetime(df_cont['time'])\n",
    "    cutoff_date = pd.to_datetime('2023-07-12')\n",
    "    \n",
    "    gauges_before_cutoff = df_cont[df_cont['time'] < cutoff_date]['reach_id'].unique()\n",
    "    print(f\"\\nGauges with data before 2023-07-12 in Continuous orbit: {len(gauges_before_cutoff)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2f4b0-d555-4b82-803d-ebc0d9ce068e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the gauge match reaches and lat/lon for plotting\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "color_dict_runCombos = {\n",
    "    'Continuous': '#D83A34',\n",
    "    'Fast': '#FD8500',\n",
    "    'Science': '#2B9EB3',\n",
    "    'Sampled': '#6610F2',\n",
    "    'gauge': 'black',\n",
    "    'Continuous-FSO': '#FFEE32',\n",
    "    'Continuous-SO': 'blue',\n",
    "}\n",
    "\n",
    "# Read all SWORD v16 geopackage files\n",
    "sword_path = '//SWORDv16/gpkg/'\n",
    "sword_files = glob.glob(f'{sword_path}*_sword_reaches_v16.gpkg')\n",
    "\n",
    "print(f\"Found {len(sword_files)} SWORD geopackage files\")\n",
    "\n",
    "# Read and combine all SWORD reach data\n",
    "sword_dfs = []\n",
    "for sword_file in sword_files:\n",
    "    print(f\"Reading {Path(sword_file).name}...\")\n",
    "    gdf = gpd.read_file(sword_file)\n",
    "    # print(gdf.columns.values.tolist())\n",
    "    # Keep only reach_id, p_lat, p_lon, and geometry columns\n",
    "    gdf = gdf[['reach_id', 'x', 'y', 'geometry']].copy()\n",
    "    sword_dfs.append(gdf)\n",
    "\n",
    "# Combine all SWORD data\n",
    "sword_reaches = pd.concat(sword_dfs, ignore_index=True)\n",
    "sword_reaches['reach_id'] = sword_reaches['reach_id'].astype(int)\n",
    "print(f\"Total SWORD reaches loaded: {len(sword_reaches)}\")\n",
    "\n",
    "# Create four DataFrames by joining gauged reach_ids with SWORD geographic data\n",
    "dfs_gauge_geo = {}\n",
    "\n",
    "for run_type, df in dfs_gauge.items():\n",
    "    df['reach_id'] = df['reach_id'].astype(int)\n",
    "    \n",
    "    # Get unique reach_ids from the gauged data\n",
    "    gauged_reaches = df[df['algo'] == 'consensus']['reach_id'].unique()\n",
    "    print(f\"\\n{run_type}: {len(gauged_reaches)} unique reach_ids\")\n",
    "    \n",
    "    # Join with SWORD geographic data\n",
    "    df_geo = sword_reaches[sword_reaches['reach_id'].isin(gauged_reaches)].copy()\n",
    "    df_geo['run_type'] = run_type\n",
    "    \n",
    "    dfs_gauge_geo[run_type] = df_geo\n",
    "    print(f\"{run_type}: {len(df_geo)} gauged reaches matched in SWORD\")\n",
    "\n",
    "def map_gauges_by_orbit(dict_of_dfs, scaling, color_dict, algo_name, common_reach_ids):\n",
    "    \"\"\"\n",
    "    Map the locations of gauged reaches colored by run type.\n",
    "    \n",
    "    Parameters:\n",
    "        dict_of_dfs (dict): Dictionary of DataFrames with geographic data\n",
    "        scaling (str): Type of scaling (e.g., 'gauge')\n",
    "        color_dict (dict): Dictionary mapping run types to colors\n",
    "        algo_name (str): Algorithm name (e.g., 'consensus')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot each run type with its corresponding color\n",
    "    for run_type, df_geo in dict_of_dfs.items():\n",
    "        if run_type in ['Continuous-SO', 'Continuous-FSO']:\n",
    "            continue\n",
    "        if len(df_geo) > 0:\n",
    "            df_geo.to_csv(f'//figs/gauge_locations_{run_type}_consensus.csv')\n",
    "            df_geo = df_geo[df_geo['reach_id'].isin(common_reach_ids)]\n",
    "            fig = plt.figure(figsize=(16, 10))\n",
    "            ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "            \n",
    "            # Add map features\n",
    "            ax.add_feature(cfeature.LAND, facecolor='lightgray', alpha=0.3)\n",
    "            ax.add_feature(cfeature.OCEAN, facecolor='lightblue', alpha=0.3)\n",
    "            ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "            ax.add_feature(cfeature.BORDERS, linewidth=0.5, linestyle=':')\n",
    "            ax.add_feature(cfeature.RIVERS, alpha=0.5)\n",
    "            \n",
    "            color = color_dict.get(run_type, 'gray')\n",
    "            \n",
    "            ax.scatter(df_geo['x'], df_geo['y'], \n",
    "                      c=color, \n",
    "                      s=50, \n",
    "                      alpha=0.5,\n",
    "                      label=run_type,\n",
    "                      transform=ccrs.PlateCarree(),\n",
    "                      edgecolors='black',\n",
    "                      linewidths=0.5)\n",
    "    \n",
    "            ax.set_extent([-180, 180, -60, 75], crs=ccrs.PlateCarree())\n",
    "            ax.gridlines(draw_labels=True, dms=True, x_inline=False, y_inline=False, alpha=0.3)\n",
    "            \n",
    "            plt.legend(loc='lower left', fontsize=12, framealpha=0.9)\n",
    "            plt.title(f'Gauged Reach Locations for {run_type}', fontsize=16, pad=20)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'//figs/gauge_locations_{run_type}_{algo_name}.png', \n",
    "                        dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "# Call the mapping function\n",
    "map_gauges_by_orbit(\n",
    "    dict_of_dfs=dfs_gauge_geo,\n",
    "    scaling='gauge',\n",
    "    color_dict=color_dict_runCombos,\n",
    "    algo_name='consensus',\n",
    "    common_reach_ids=common_reach_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4a84a-42fb-4ab9-885a-41fe19735594",
   "metadata": {},
   "source": [
    "## Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee55ce3-3962-4098-8eb5-003aedd1b18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "priors_a = pd.read_csv('/prior_q_a_fsReaches.csv')\n",
    "priors_b = pd.read_csv('/prior_q_b_fsReaches.csv')\n",
    "priors_c = pd.read_csv('/prior_q_c_fsReaches.csv')\n",
    "priors_e = pd.read_csv('/prior_q_e_fsReaches.csv')\n",
    "\n",
    "\n",
    "\n",
    "dfs_priors = {\n",
    "    'Fast': priors_a,\n",
    "    'Science': priors_b,\n",
    "    'Continuous': priors_c,\n",
    "    'Sampled': priors_e,\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c11b5d-9f50-4ae1-9677-dd8e5daaab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match gauge data to prior data\n",
    "\n",
    "dfs_gauge_priors = match_priors_to_gauge_data(dfs_gauge, dfs_priors)\n",
    "\n",
    "# Verify the results\n",
    "for orbit_type, df in dfs_gauge_priors.items():\n",
    "    print(f\"\\n{orbit_type} DataFrame:\")\n",
    "    print(df.columns)\n",
    "    \n",
    "    # Only print head if the columns exist\n",
    "    try:\n",
    "        print(df[['reach_id', 'time', 'month', 'matched_model_monthly_q', 'matched_gauge_monthly_q', 'matched_gauge_CAL_flag']].head())\n",
    "    except KeyError:\n",
    "        print(\"Unable to print selected columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c4a2f-64d4-4526-8a9d-00bc8c2124fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add continuous orbit split\n",
    "priors_c_fast = dfs_gauge_priors['Continuous'][pd.to_datetime(dfs_gauge_priors['Continuous']['time']) < divide_date]\n",
    "priors_c_science = dfs_gauge_priors['Continuous'][pd.to_datetime(dfs_gauge_priors['Continuous']['time']) >= divide_date]\n",
    "\n",
    "\n",
    "dfs_gauge_priors = {\n",
    "    'Fast': dfs_gauge_priors['Fast'],\n",
    "    'Science': dfs_gauge_priors['Science'],\n",
    "    'Continuous': dfs_gauge_priors['Continuous'],\n",
    "    'Sampled': dfs_gauge_priors['Sampled'],\n",
    "    'Continuous-FSO': priors_c_fast,\n",
    "    'Continuous-SO': priors_c_science\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1b987-3255-4d61-afc5-b19a92ad1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the monthly prior and gauge/consensus discharge \n",
    "\n",
    "plot_multiple_reaches(dfs_gauge_priors, color_dict, num_reaches=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d554ddcd-5038-4a03-ab58-1bb29d6a04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_gauge_priors_pivoted = {}    \n",
    "for label, df in dfs_gauge_priors.items():\n",
    "    # Prepare the DataFrame\n",
    "    df = df.copy()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df[(df['Q'] > 1) & (df['Q'] < 1e7)]\n",
    "    \n",
    "    # Print columns to debug\n",
    "    print(f\"Columns in {label}:\", list(df.columns))\n",
    "    \n",
    "    # Add matched_model_monthly_q as an algorithm\n",
    "    model_df = df.copy()\n",
    "    model_df = model_df[model_df['algo'] == 'consensus']\n",
    "    model_df['algo'] = 'monthly_priors'\n",
    "    \n",
    "    # Use .loc to set Q column\n",
    "    model_df.loc[:, 'Q'] = model_df['matched_model_monthly_q']\n",
    "    \n",
    "    # Combine original and model DataFrames\n",
    "    full_df = pd.concat([df, model_df], ignore_index=True)\n",
    "    dfs_gauge_priors_pivoted[label] = full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7692b53-b1dd-4428-b905-e05d5e4f5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get dfs_gauge_priors and compare metric distribution\n",
    "common_reach_ids = plot_algorithm_metric_cdfs_from_dict(\n",
    "    dict_of_dfs=dfs_gauge,\n",
    "    scaling='gauge',\n",
    "    color_dict=color_dict_runCombos,\n",
    "    algo_name='consensus',\n",
    "    dfs_gauge_priors=dfs_gauge_priors \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fbf4e-b00b-4886-8d7b-d0db87f7a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal log ratio by orbit: compare priors to gauge\n",
    "plot_seasonal_log_ratio_by_orbit(\n",
    "    dfs_dict=dfs_gauge_priors_pivoted,\n",
    "    consensus_algo='consensus',\n",
    "    gauge_algo='gauge_swot_match',\n",
    "    monthly_prior_algo='monthly_priors',\n",
    "    output_dir='//figs/'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec3631f-8396-463c-9b24-d7849c1a5f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal log ratio by continent: compare priors to gauge\n",
    "\n",
    "plot_seasonal_log_ratio_by_continent(\n",
    "    dfs_dict=dfs_gauge_priors_pivoted,\n",
    "    consensus_algo='consensus',\n",
    "    gauge_algo='gauge_swot_match',\n",
    "    monthly_prior_algo='monthly_priors',\n",
    "    output_dir='//figs/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fedc54-989f-4217-a65f-fa8148a21ec5",
   "metadata": {},
   "source": [
    "### Comparisons and Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30678d5-32cd-4025-925d-720a503ec3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp, wilcoxon, shapiro\n",
    "\n",
    "# Grouped boxplot comparing prior/gauge by orbit\n",
    "\n",
    "plot_grouped_boxplot_differences(\n",
    "    dict_of_dfs=dfs_gauge,\n",
    "    algo_name='consensus',\n",
    "    color_dict=color_dict_runCombos,\n",
    "    plot=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf68ed-6eec-4dfa-986b-2b1fb602733b",
   "metadata": {},
   "source": [
    "## Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b83c1-a807-475c-9c70-249baca75b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped boxplot comparing prior/gauge by continent \n",
    "\n",
    "#By Reach\n",
    "\n",
    "\n",
    "plot_grouped_boxplot_runs_by_reach(dfs_dict=dfs_gauge, consensus_algo='consensus')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf50180-7be1-45ad-8d04-1eacbe5d81a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantile POint performance \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "results_by_df = plot_nd_scatter_by_quantile_per_df(\n",
    "    dfs_dict=dfs_gauge_fullRange,\n",
    "    consensus_algo='consensus',\n",
    "    gauge_algo='gauge'\n",
    ")\n",
    "\n",
    "all_tables = []\n",
    "\n",
    "for orbit_name, res in results_by_df.items():\n",
    "    if orbit_name in ['Continuous-SO', 'Continuous-FSO']:\n",
    "        continue\n",
    "\n",
    "    # Extract metrics and build DataFrame\n",
    "    metrics = res['metrics']\n",
    "    metrics_df = pd.DataFrame(metrics).T\n",
    "\n",
    "    # Add orbit name as a column\n",
    "    metrics_df.insert(0, \"Orbit\", orbit_name)\n",
    "\n",
    "    # Add Quantile column (from index)\n",
    "    metrics_df = metrics_df.reset_index().rename(columns={'index': 'Quantile'})\n",
    "\n",
    "    all_tables.append(metrics_df)\n",
    "\n",
    "# Combine all into one table\n",
    "final_table = pd.concat(all_tables)\n",
    "\n",
    "# Sort by Orbit then Quantile\n",
    "final_table = final_table.sort_values(by=[\"Quantile\"]).reset_index(drop=True)\n",
    "\n",
    "final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bc50a-34b0-4d6d-b97c-8718e58edce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import wilcoxon, binomtest\n",
    "\n",
    "    \n",
    "#Algo differences by continent w/stats\n",
    "            \n",
    "plot_selected_algorithm_differences_grouped_by_continent(\n",
    "    dict_of_dfs=dfs_gauge,\n",
    "    algo_name='consensus',\n",
    "    color_dict=color_dict,\n",
    "    plot=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f1d494-6523-4800-9f34-f1e8eb56a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib import cm  # old-style import for compatibility\n",
    "\n",
    "\n",
    "plot_per_reach_metric_difference_heatmaps_switched_axes(\n",
    "    dict_of_dfs=dfs_gauge,\n",
    "    algo_name='consensus'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd0c20-7fff-4568-bad6-11a9f0e2b41e",
   "metadata": {},
   "source": [
    "## Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc3eae-7498-4a71-a233-f15f0692ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REACH\n",
    "\n",
    "plot_orbitwise_log_ratio_vs_gauge_by_season(dfs_dict=dfs_gauge, consensus_label='consensus', gauge_label='gauge_swot_match', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc8d042-b0da-47b9-87e9-65722cf17b24",
   "metadata": {},
   "source": [
    "# Orbit Regime Characteristics Gauge Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3356d-2395-47ab-b517-44a6591c68db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regime\n",
    "\n",
    "\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='consensus')\n",
    "# Combine and save\n",
    "overall_summary_all_cons = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "\n",
    "overall_summary_all_cons = summarize_peaks(overall_summary_all_cons)\n",
    "\n",
    "\n",
    "print(overall_summary_all_cons.columns.values.tolist())\n",
    "overall_summary_all_cons.to_csv('//data/abcd_perm/consensus_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "#Gauge full Range\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='gauge')\n",
    "# Combine and save\n",
    "aggregated_q_overall_gauge_fullRange = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "\n",
    "aggregated_q_overall_gauge_fullRange = summarize_peaks(aggregated_q_overall_gauge_fullRange)\n",
    "\n",
    "\n",
    "aggregated_q_overall_gauge_fullRange.to_csv('//data/abcd_perm/gauge_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "#Gauge SWOT Match\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='gauge_swot_match')\n",
    "# Combine and save\n",
    "overall_summary_all_gauge_swot = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "\n",
    "overall_summary_all_gauge_swot = summarize_peaks(overall_summary_all_gauge_swot)\n",
    "\n",
    "overall_summary_all_gauge_swot.to_csv('//data/abcd_perm/gauge_swot_match_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='metroman')\n",
    "\n",
    "# Combine and save\n",
    "overall_summary_all_metroman = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "overall_summary_all_metroman = summarize_peaks(overall_summary_all_metroman)\n",
    "\n",
    "overall_summary_all_metroman.to_csv('//data/abcd_perm/metroman_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='sic4dvar')\n",
    "# Combine and save\n",
    "overall_summary_all_sic4dvar = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "\n",
    "overall_summary_all_sic4dvar = summarize_peaks(overall_summary_all_sic4dvar)\n",
    "\n",
    "overall_summary_all_sic4dvar.to_csv('//data/abcd_perm/sic4dvar_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='momma')\n",
    "overall_summary_all_momma = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "\n",
    "overall_summary_all_momma = summarize_peaks(overall_summary_all_momma)\n",
    "\n",
    "# Combine and save\n",
    "overall_summary_all_momma.to_csv('//data/abcd_perm/momma_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "aggregated_q_overall = summarize_overall_Q(dfs_q=dfs_gauge_fullRange, algo='neobam')\n",
    "overall_summary_all_geobam = pd.concat(aggregated_q_overall.values(), ignore_index=True)\n",
    "\n",
    "overall_summary_all_geobam = summarize_peaks(overall_summary_all_geobam)\n",
    "\n",
    "\n",
    "# Combine and save\n",
    "overall_summary_all_geobam.to_csv('//data/abcd_perm/neobam_gauges_regime_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20487566-5064-46a4-b193-4853ad559cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By season\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='consensus')\n",
    "# Combine and save\n",
    "overall_summary_all_cons_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "print(overall_summary_all_cons_season.columns.values.tolist())\n",
    "overall_summary_all_cons_season.to_csv('//data/abcd_perm/consensus_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "#Gauge full Range\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='gauge')\n",
    "# Combine and save\n",
    "aggregated_q_overall_gauge_fullRange_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "aggregated_q_overall_gauge_fullRange_season.to_csv('//data/abcd_perm/gauge_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "#Gauge SWOT Match\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='gauge_swot_match')\n",
    "# Combine and save\n",
    "overall_summary_all_gauge_swot_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "overall_summary_all_gauge_swot_season.to_csv('/gauge_swot_match_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='metroman')\n",
    "\n",
    "# Combine and save\n",
    "overall_summary_all_metroman_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "overall_summary_all_metroman_season.to_csv('/metroman_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='sic4dvar')\n",
    "# Combine and save\n",
    "overall_summary_all_sic4dvar_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "overall_summary_all_sic4dvar_season.to_csv('/sic4dvar_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "\n",
    "\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='momma')\n",
    "overall_summary_all_momma_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "# Combine and save\n",
    "overall_summary_all_momma_season.to_csv('/momma_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')\n",
    "\n",
    "aggregated_q_overall_season = summarize_overall_Q_by_season(dfs_q=dfs_gauge_fullRange, algo='neobam')\n",
    "overall_summary_all_geobam_season = pd.concat(aggregated_q_overall_season.values(), ignore_index=True)\n",
    "\n",
    "\n",
    "# Combine and save\n",
    "overall_summary_all_geobam_season.to_csv('/neobam_gauges_regime_season_summary.csv', float_format=\"%.2f\", index=False)\n",
    "print('save successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e083f8e-af82-4dc8-8c21-abd8aa18818d",
   "metadata": {},
   "source": [
    "#### Flow Duration Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df697be3-4cab-4fe1-beb3-c432fe40aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "\n",
    "\n",
    "color_dict_runCombos = {\n",
    "    'Continuous': '#D83A34',\n",
    "    'Fast': '#FD8500',\n",
    "    'Science': '#2B9EB3',\n",
    "    'Sampled': '#6610F2',\n",
    "    'gauge': 'black',\n",
    "    'Continuous-FSO': '#FFEE32',\n",
    "    'Continuous-SO': 'turquoise',\n",
    "}\n",
    "\n",
    "summary_metrics = plot_reach_consensus_cdfs(\n",
    "    df_dict=dfs_gauge_fullRange,\n",
    "    variable='Q',\n",
    "    algo='consensus',\n",
    "    color_dict=color_dict_runCombos\n",
    ")\n",
    "\n",
    "summary_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fe51e7-0f6f-4fe2-8922-f547e3ab427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "\n",
    "#TAKES AWHILE - need to parallelize\n",
    "summary_metrics = plot_reach_cdfs_horizontal_with_ks_emd(\n",
    "    df_dict=dfs_gauge_fullRange,\n",
    "    variable='Q',\n",
    "    algos=['consensus', 'gauge', 'gauge_swot_match']\n",
    ")\n",
    "\n",
    "# Display the table\n",
    "print(summary_metrics.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a1609f-ad4b-46af-b1b3-1f4711fada24",
   "metadata": {},
   "source": [
    "#### Percentile analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27702861-75cc-4afd-b007-d912b804d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_type = '90'\n",
    "\n",
    "for orb in ['Fast', 'Science', 'Sampled', 'Continuous']:\n",
    "    \n",
    "    seasonal_summary_cont = overall_summary[overall_summary['run'] == orb].copy()\n",
    "\n",
    "    # --- Add season columns based on peak max_date ---\n",
    "    for col in seasonal_summary_cont.columns:\n",
    "        if col.endswith('_max_date') and peak_type in col:  # or use '_start' if that's what defines peak timing\n",
    "            season_col = col.replace('_max_date', '_season')\n",
    "            overall_summary[season_col] = overall_summary[col].apply(\n",
    "                lambda d: get_season_orbits(d) if pd.notna(d) else np.nan\n",
    "            )\n",
    "\n",
    "\n",
    "    # Melt only the columns that exist in df\n",
    "    season_cols = [col for col in seasonal_summary_cont.columns if col.endswith('_season')]\n",
    "    df_melt = seasonal_summary_cont.melt(\n",
    "        id_vars=['algo', 'reach_id'],  \n",
    "        value_vars=season_cols,\n",
    "        var_name='peak',\n",
    "        value_name='season'\n",
    "    )\n",
    "    # Drop missing season values\n",
    "    df_melt = df_melt.dropna(subset=['season'])\n",
    "\n",
    "    # Filter for specific orbits\n",
    "    df_melt = df_melt[df_melt['algo'].isin(['consensus', 'gauge', 'sic4dvar', 'neobam', 'metroman', 'momma'])]\n",
    "\n",
    "    # --- Count peaks per reach_id ---\n",
    "    counts_per_reach = (\n",
    "        df_melt.groupby(['reach_id', 'algo', 'season'])\n",
    "        .size()\n",
    "        .reset_index(name='n_peaks')\n",
    "    )\n",
    "\n",
    "    # --- Average across reach_ids ---\n",
    "    avg_counts = (\n",
    "        counts_per_reach.groupby(['algo', 'season'])['n_peaks']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Check if there's data to plot\n",
    "    if avg_counts.empty or avg_counts['n_peaks'].isna().all():\n",
    "        print(f\"No data to plot for orbit: {orb}\")\n",
    "        continue\n",
    "\n",
    "    # --- Plot as barplot ---\n",
    "    plt.figure(figsize=(24, 12))\n",
    "    ax = sns.barplot(\n",
    "        data=avg_counts,\n",
    "        x='season',\n",
    "        y='n_peaks',\n",
    "        hue='algo',\n",
    "        palette=color_dict,\n",
    "        hue_order=['gauge', 'consensus', 'sic4dvar', 'neobam', 'momma', 'metroman']\n",
    "    )\n",
    "\n",
    "    # --- Annotate bars ---\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        if pd.isna(height) or height <= 0:\n",
    "            continue\n",
    "        ax.annotate(\n",
    "            f\"{height:.1f}\",                   # one decimal place\n",
    "            (p.get_x() + p.get_width() / 2., height),\n",
    "            ha='center', va='bottom',\n",
    "            fontsize=25, color='black',\n",
    "            xytext=(0, 3), textcoords='offset points'\n",
    "        )\n",
    "    \n",
    "    # --- Add padding above bars for annotations ---\n",
    "    ymax = avg_counts['n_peaks'].max()\n",
    "    if pd.notna(ymax) and np.isfinite(ymax):  # Check if ymax is valid\n",
    "        plt.ylim(0, ymax * 1.15)  # add 15% headroom (tweak as needed)\n",
    "\n",
    "    plt.title(f\"{orb} Run - Q{peak_type}\", fontsize=44)\n",
    "    plt.ylabel(f\"Average Reach Q{peak_type} Events\", fontsize=44)\n",
    "    plt.xticks(fontsize=40)\n",
    "    plt.yticks(fontsize=40)\n",
    "    plt.xlabel(\"Season\", fontsize=44)\n",
    "    plt.legend(title='Algorithm', title_fontsize=28, fontsize=26)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'//figs/seasonPeakCount_{orb}_{peak_type}.png', dpi=350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94abd80-e422-4d1a-a822-5e6826d8e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REVISIT TIME PLOTS\n",
    "\n",
    "# Color dictionary\n",
    "# color_dict_timeseries = {\n",
    "#     'Fast': 'lightskyblue', \n",
    "#     'Science': 'mediumblue', \n",
    "#     'Continuous': 'darkviolet', \n",
    "#     'Sampled': 'crimson', \n",
    "#     'gauge': 'darkgrey'\n",
    "# }\n",
    "\n",
    "get_revisit_times_overall(dfs_q=dfs_gauge_fullRange, color_dict_timeseries=color_dict_timeseries)\n",
    "get_revisit_times(dfs_q=dfs_gauge_fullRange, color_dict_timeseries=color_dict_timeseries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9f350-ba67-4d96-b18b-99e3cd232824",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_q90_summary_by_run(overall_summary, peaks_long, overlaps, color_dict_timeseries, peak_type=\"10\")\n",
    "plot_q90_summary_by_run(overall_summary, peaks_long, overlaps, color_dict_timeseries, peak_type=\"90\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65e4480-33a2-4216-8d10-389edce7ffa2",
   "metadata": {},
   "source": [
    "# Algo Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afb7a4-ffe2-4f3f-98d7-2ef690ad23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call summary of algos and print\n",
    "summary_algo_df = plot_metric_cdfs_by_algo(\n",
    "    dict_of_dfs=dfs_gauge,    # your dict of DataFrames keyed by orbit labels\n",
    "    scaling='gauge',\n",
    "    color_dict=color_dict_timeseries,  # your colors keyed by orbit labels (dict keys)\n",
    "    algo_name=None          # or specify algo like 'consensus'\n",
    ")\n",
    "summary_algo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcf4692-4ff4-48b0-b58a-b7780bc8c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_algo_df.sort_values(by=['Metric', 'Orbit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d89136-feb4-4fc0-a2ba-8d0f4d366ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics by orbit/run\n",
    "\n",
    "combined_df = plot_metric_cdfs_faceted_by_orbit(\n",
    "    dict_of_dfs=dfs_gauge,          # your dict of DataFrames keyed by orbit labels\n",
    "    scaling='gauge',\n",
    "    color_dict_algo=color_dict,     # your colors keyed by algo names\n",
    "    algo_name=None                  # or specify algo like 'consensus'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff03d5c-011a-42e4-a7d1-d758c710d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_median_p67_by_orbit_algo_metric(combined_df):\n",
    "    \"\"\"\n",
    "    Summarize median, 67th percentile (p67), and count of unique reach_ids (n)\n",
    "    for each algorithm  metric  orbit combination.\n",
    "\n",
    "    Parameters:\n",
    "    - combined_df (DataFrame): with columns:\n",
    "        ['Metric', 'Value', 'algo', 'orbit', 'reach_id']\n",
    "\n",
    "    Returns:\n",
    "    - summary_df (DataFrame): with columns:\n",
    "        ['orbit', 'Metric', 'algo', 'median', 'p67', 'n']\n",
    "    \"\"\"\n",
    "    summary_df = (\n",
    "        combined_df\n",
    "        .groupby(['orbit', 'Metric', 'algo'])\n",
    "        .agg(\n",
    "            median=('Value', lambda x: np.median(x.dropna())),\n",
    "            p67=('Value', lambda x: np.percentile(x.dropna(), 67)),\n",
    "            n=('reach_id', lambda x: x.nunique())\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    return summary_df\n",
    "\n",
    "summary = summarize_median_p67_by_orbit_algo_metric(combined_df)\n",
    "summary[summary['Metric'].isin(['r','nBIAS','NSE'])].sort_values(['algo','Metric'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b02471-e026-4213-ac94-c327c3bfc969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo and Gauge CV\n",
    "\n",
    "\n",
    "algos_to_plot = ['hivdi', 'sic4dvar', 'momma', 'neobam', 'consensus', 'geobam', 'metroman', 'gauge_swot_match','gauge']\n",
    "\n",
    "plot_cdf_coeff(dfs_q=dfs_gauge_fullRange, color_dict=color_dict, algos_to_plot = algos_to_plot)\n",
    "\n",
    "\n",
    "#RMD\n",
    "    \n",
    "cdfPlot_RMD(dfs_q=dfs_gauge, color_dict=color_dict, column_to_plot = 'RMD_cons')\n",
    "#cdfPlot_RMD(dfs_q=dfs_q, color_dict=color_dict, column_to_plot = 'RMD_gauge')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-swotEF]",
   "language": "python",
   "name": "conda-env-.conda-swotEF-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
